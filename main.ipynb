{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ODL Assignment (Solution Development)\n",
    "**Group number**: 15\\\n",
    "**Group leader**: Choong Man Shun (TP051283)\\\n",
    "**Group members**:\n",
    "* Chew Cheng Yong (TP051338)\n",
    "* Wong Poh Yee (TP051079)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table of Contents\n",
    "[1. Exploratory Data Analysis (EDA)](#eda)\\\n",
    "[2. Data Preprocessing](#data_preprocessing)\\\n",
    "[4. Model Implementation](#model_implementation)\n",
    "- [4.1 ?](#model_1)\n",
    "  - [4.1.1 Base Model](#base_model_1)\n",
    "  - [4.1.2 Model Hyperparameter Tuning](#model_hyperparameter_tuning_1)\n",
    "  - [4.1.3 Final Model](#final_model_1)\n",
    "- [4.2 ?](#model_2)\n",
    "  - [4.2.1 Base Model](#base_model_2)\n",
    "  - [4.2.2 Model Hyperparameter Tuning](#model_hyperparameter_tuning_2)\n",
    "  - [4.2.3 Final Model](#final_model_2)\n",
    "- [4.3 ?](#model_3)\n",
    "  - [4.3.1 Base Model](#base_model_3)\n",
    "  - [4.3.2 Model Hyperparameter Tuning](#model_hyperparameter_tuning_3)\n",
    "  - [4.3.3 Final Model](#final_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Exploratory Data Analysis (EDA) <a id=\"eda\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n0          1    15634602  Hargrave          619    France  Female   42   \n1          2    15647311      Hill          608     Spain  Female   41   \n2          3    15619304      Onio          502    France  Female   42   \n3          4    15701354      Boni          699    France  Female   39   \n4          5    15737888  Mitchell          850     Spain  Female   43   \n\n   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0       2       0.00              1          1               1   \n1       1   83807.86              1          0               1   \n2       8  159660.80              3          1               0   \n3       1       0.00              2          0               0   \n4       2  125510.82              1          1               1   \n\n   EstimatedSalary  Exited  \n0        101348.88       1  \n1        112542.58       0  \n2        113931.57       1  \n3         93826.63       0  \n4         79084.10       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n9995       9996    15606229   Obijiaku          771    France    Male   39   \n9996       9997    15569892  Johnstone          516    France    Male   35   \n9997       9998    15584532        Liu          709    France  Female   36   \n9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n9999      10000    15628319     Walker          792    France  Female   28   \n\n      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n9995       5       0.00              2          1               0   \n9996      10   57369.61              1          1               1   \n9997       7       0.00              1          0               1   \n9998       3   75075.31              2          1               0   \n9999       4  130142.79              1          1               0   \n\n      EstimatedSalary  Exited  \n9995         96270.64       0  \n9996        101699.77       0  \n9997         42085.58       1  \n9998         92888.52       1  \n9999         38190.78       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9995</th>\n      <td>9996</td>\n      <td>15606229</td>\n      <td>Obijiaku</td>\n      <td>771</td>\n      <td>France</td>\n      <td>Male</td>\n      <td>39</td>\n      <td>5</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>96270.64</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>9997</td>\n      <td>15569892</td>\n      <td>Johnstone</td>\n      <td>516</td>\n      <td>France</td>\n      <td>Male</td>\n      <td>35</td>\n      <td>10</td>\n      <td>57369.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101699.77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>9998</td>\n      <td>15584532</td>\n      <td>Liu</td>\n      <td>709</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>36</td>\n      <td>7</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42085.58</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>9999</td>\n      <td>15682355</td>\n      <td>Sabbatini</td>\n      <td>772</td>\n      <td>Germany</td>\n      <td>Male</td>\n      <td>42</td>\n      <td>3</td>\n      <td>75075.31</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92888.52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>10000</td>\n      <td>15628319</td>\n      <td>Walker</td>\n      <td>792</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>28</td>\n      <td>4</td>\n      <td>130142.79</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38190.78</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 14)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\ncount  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \nmean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \nstd     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \nmin        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \nmax    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n\n             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\ncount   10000.000000   10000.000000  10000.00000    10000.000000   \nmean    76485.889288       1.530200      0.70550        0.515100   \nstd     62397.405202       0.581654      0.45584        0.499797   \nmin         0.000000       1.000000      0.00000        0.000000   \n25%         0.000000       1.000000      0.00000        0.000000   \n50%     97198.540000       1.000000      1.00000        1.000000   \n75%    127644.240000       2.000000      1.00000        1.000000   \nmax    250898.090000       4.000000      1.00000        1.000000   \n\n       EstimatedSalary        Exited  \ncount     10000.000000  10000.000000  \nmean     100090.239881      0.203700  \nstd       57510.492818      0.402769  \nmin          11.580000      0.000000  \n25%       51002.110000      0.000000  \n50%      100193.915000      0.000000  \n75%      149388.247500      0.000000  \nmax      199992.480000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>CreditScore</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.00000</td>\n      <td>1.000000e+04</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.00000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5000.50000</td>\n      <td>1.569094e+07</td>\n      <td>650.528800</td>\n      <td>38.921800</td>\n      <td>5.012800</td>\n      <td>76485.889288</td>\n      <td>1.530200</td>\n      <td>0.70550</td>\n      <td>0.515100</td>\n      <td>100090.239881</td>\n      <td>0.203700</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2886.89568</td>\n      <td>7.193619e+04</td>\n      <td>96.653299</td>\n      <td>10.487806</td>\n      <td>2.892174</td>\n      <td>62397.405202</td>\n      <td>0.581654</td>\n      <td>0.45584</td>\n      <td>0.499797</td>\n      <td>57510.492818</td>\n      <td>0.402769</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>1.556570e+07</td>\n      <td>350.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>11.580000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2500.75000</td>\n      <td>1.562853e+07</td>\n      <td>584.000000</td>\n      <td>32.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>51002.110000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5000.50000</td>\n      <td>1.569074e+07</td>\n      <td>652.000000</td>\n      <td>37.000000</td>\n      <td>5.000000</td>\n      <td>97198.540000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>100193.915000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7500.25000</td>\n      <td>1.575323e+07</td>\n      <td>718.000000</td>\n      <td>44.000000</td>\n      <td>7.000000</td>\n      <td>127644.240000</td>\n      <td>2.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>149388.247500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10000.00000</td>\n      <td>1.581569e+07</td>\n      <td>850.000000</td>\n      <td>92.000000</td>\n      <td>10.000000</td>\n      <td>250898.090000</td>\n      <td>4.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>199992.480000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Surname Geography Gender\ncount    10000     10000  10000\nunique    2932         3      2\ntop      Smith    France   Male\nfreq        32      5014   5457\nmean       NaN       NaN    NaN\nstd        NaN       NaN    NaN\nmin        NaN       NaN    NaN\n25%        NaN       NaN    NaN\n50%        NaN       NaN    NaN\n75%        NaN       NaN    NaN\nmax        NaN       NaN    NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Surname</th>\n      <th>Geography</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000</td>\n      <td>10000</td>\n      <td>10000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2932</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Smith</td>\n      <td>France</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>32</td>\n      <td>5014</td>\n      <td>5457</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').select_dtypes(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "RowNumber          0\nCustomerId         0\nSurname            0\nCreditScore        0\nGeography          0\nGender             0\nAge                0\nTenure             0\nBalance            0\nNumOfProducts      0\nHasCrCard          0\nIsActiveMember     0\nEstimatedSalary    0\nExited             0\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Text(0, 0, 'Age'),\n Text(1, 0, 'Balance'),\n Text(2, 0, 'EstimatedSalary'),\n Text(3, 0, 'CustomerId'),\n Text(4, 0, 'HasCrCard'),\n Text(5, 0, 'Tenure'),\n Text(6, 0, 'RowNumber'),\n Text(7, 0, 'CreditScore'),\n Text(8, 0, 'NumOfProducts'),\n Text(9, 0, 'IsActiveMember')]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor_df = df.drop(columns=\"Exited\")\n",
    "corr_df = predictor_df.corrwith(df.Exited).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "barplot = sns.barplot(x=corr_df.index, y=corr_df.values, orient=\"v\")\n",
    "barplot.bar_label(barplot.containers[0])\n",
    "barplot.set(title=\"Correlation with Exited\", xlabel=\"Columns\", ylabel=\"Correlation\")\n",
    "barplot.set_xticklabels(barplot.get_xticklabels(), rotation=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "barplot = sns.countplot(x=df.Exited)\n",
    "barplot.set(\n",
    "    title=\"Exited Count\",\n",
    "    xlabel=\"Exited\",\n",
    "    ylabel=\"Count\",\n",
    "    xticklabels=[\"0 (No)\", \"1 (Yes)\"]\n",
    ")\n",
    "\n",
    "for p in barplot.patches:\n",
    "    percentage = p.get_height() / len(df)\n",
    "    x = p.get_x() + 0.2\n",
    "    y = p.get_height() + 60\n",
    "    barplot.annotate(f\"{percentage:.2%} ({p.get_height()})\", (x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Data Preprocessing <a id=\"data_preprocessing\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n0             619    France  Female   42       2       0.00              1   \n1             608     Spain  Female   41       1   83807.86              1   \n2             502    France  Female   42       8  159660.80              3   \n3             699    France  Female   39       1       0.00              2   \n4             850     Spain  Female   43       2  125510.82              1   \n...           ...       ...     ...  ...     ...        ...            ...   \n9995          771    France    Male   39       5       0.00              2   \n9996          516    France    Male   35      10   57369.61              1   \n9997          709    France  Female   36       7       0.00              1   \n9998          772   Germany    Male   42       3   75075.31              2   \n9999          792    France  Female   28       4  130142.79              1   \n\n      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n0             1               1        101348.88       1  \n1             0               1        112542.58       0  \n2             1               0        113931.57       1  \n3             0               0         93826.63       0  \n4             1               1         79084.10       0  \n...         ...             ...              ...     ...  \n9995          1               0         96270.64       0  \n9996          1               1        101699.77       0  \n9997          0               1         42085.58       1  \n9998          1               0         92888.52       1  \n9999          1               0         38190.78       0  \n\n[10000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>771</td>\n      <td>France</td>\n      <td>Male</td>\n      <td>39</td>\n      <td>5</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>96270.64</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>516</td>\n      <td>France</td>\n      <td>Male</td>\n      <td>35</td>\n      <td>10</td>\n      <td>57369.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101699.77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>709</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>36</td>\n      <td>7</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42085.58</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>772</td>\n      <td>Germany</td>\n      <td>Male</td>\n      <td>42</td>\n      <td>3</td>\n      <td>75075.31</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92888.52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>792</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>28</td>\n      <td>4</td>\n      <td>130142.79</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38190.78</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows  11 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = df.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\"])\n",
    "\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n0             619    France  Female   42       2       0.00              1   \n1             608     Spain  Female   41       1   83807.86              1   \n2             502    France  Female   42       8  159660.80              3   \n3             699    France  Female   39       1       0.00              2   \n4             850     Spain  Female   43       2  125510.82              1   \n...           ...       ...     ...  ...     ...        ...            ...   \n9995          771    France    Male   39       5       0.00              2   \n9996          516    France    Male   35      10   57369.61              1   \n9997          709    France  Female   36       7       0.00              1   \n9998          772   Germany    Male   42       3   75075.31              2   \n9999          792    France  Female   28       4  130142.79              1   \n\n      HasCrCard  IsActiveMember  EstimatedSalary  \n0             1               1        101348.88  \n1             0               1        112542.58  \n2             1               0        113931.57  \n3             0               0         93826.63  \n4             1               1         79084.10  \n...         ...             ...              ...  \n9995          1               0         96270.64  \n9996          1               1        101699.77  \n9997          0               1         42085.58  \n9998          1               0         92888.52  \n9999          1               0         38190.78  \n\n[10000 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>771</td>\n      <td>France</td>\n      <td>Male</td>\n      <td>39</td>\n      <td>5</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>96270.64</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>516</td>\n      <td>France</td>\n      <td>Male</td>\n      <td>35</td>\n      <td>10</td>\n      <td>57369.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101699.77</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>709</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>36</td>\n      <td>7</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42085.58</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>772</td>\n      <td>Germany</td>\n      <td>Male</td>\n      <td>42</td>\n      <td>3</td>\n      <td>75075.31</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92888.52</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>792</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>28</td>\n      <td>4</td>\n      <td>130142.79</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38190.78</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows  10 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = filter_df.drop(columns=\"Exited\")\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0       1\n1       0\n2       1\n3       0\n4       0\n       ..\n9995    0\n9996    0\n9997    1\n9998    1\n9999    0\nName: Exited, Length: 10000, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = filter_df.Exited\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Geography  Gender\n0       France  Female\n1        Spain  Female\n2       France  Female\n3       France  Female\n4        Spain  Female\n...        ...     ...\n9995    France    Male\n9996    France    Male\n9997    France  Female\n9998   Germany    Male\n9999    France  Female\n\n[10000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Geography</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spain</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>France</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>France</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Spain</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>France</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>France</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>France</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>Germany</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>France</td>\n      <td>Female</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows  2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_objects = x.select_dtypes(include=[\"object\"])\n",
    "\n",
    "x_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n0             619   42       2       0.00              1          1   \n1             608   41       1   83807.86              1          0   \n2             502   42       8  159660.80              3          1   \n3             699   39       1       0.00              2          0   \n4             850   43       2  125510.82              1          1   \n...           ...  ...     ...        ...            ...        ...   \n9995          771   39       5       0.00              2          1   \n9996          516   35      10   57369.61              1          1   \n9997          709   36       7       0.00              1          0   \n9998          772   42       3   75075.31              2          1   \n9999          792   28       4  130142.79              1          1   \n\n      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n0                  1        101348.88                 1                  0   \n1                  1        112542.58                 0                  0   \n2                  0        113931.57                 1                  0   \n3                  0         93826.63                 1                  0   \n4                  1         79084.10                 0                  0   \n...              ...              ...               ...                ...   \n9995               0         96270.64                 1                  0   \n9996               1        101699.77                 1                  0   \n9997               1         42085.58                 1                  0   \n9998               0         92888.52                 0                  1   \n9999               0         38190.78                 1                  0   \n\n      Geography_Spain  Gender_Male  \n0                   0            0  \n1                   1            0  \n2                   0            0  \n3                   0            0  \n4                   1            0  \n...               ...          ...  \n9995                0            1  \n9996                0            1  \n9997                0            0  \n9998                0            1  \n9999                0            0  \n\n[10000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Geography_France</th>\n      <th>Geography_Germany</th>\n      <th>Geography_Spain</th>\n      <th>Gender_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>771</td>\n      <td>39</td>\n      <td>5</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>96270.64</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>516</td>\n      <td>35</td>\n      <td>10</td>\n      <td>57369.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101699.77</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>709</td>\n      <td>36</td>\n      <td>7</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42085.58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>772</td>\n      <td>42</td>\n      <td>3</td>\n      <td>75075.31</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92888.52</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>792</td>\n      <td>28</td>\n      <td>4</td>\n      <td>130142.79</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38190.78</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows  12 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder(drop=\"if_binary\", sparse=False)\n",
    "x_one_hot_array = one_hot_encoder.fit_transform(x_objects)\n",
    "\n",
    "x_one_hot = x.select_dtypes(exclude=[\"object\"])\n",
    "object_columns = one_hot_encoder.get_feature_names_out()\n",
    "\n",
    "for column, values in zip(object_columns, x_one_hot_array.T):\n",
    "    x_one_hot[column] = values.astype(int)\n",
    "\n",
    "x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training x: (7000, 12)\n",
      "Shape of training y: (7000,)\n",
      "Shape of testing x: (3000, 12)\n",
      "Shape of testing y: (3000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_one_hot, y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "print(\"Shape of training x:\", x_train.shape)\n",
    "print(\"Shape of training y:\", y_train.shape)\n",
    "print(\"Shape of testing x:\", x_test.shape)\n",
    "print(\"Shape of testing y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.09792126, -0.55759842, -1.03635146, ..., -0.56987189,\n        -0.5731713 ,  0.92295821],\n       [-1.12612023,  0.01725942,  0.69700901, ..., -0.56987189,\n        -0.5731713 ,  0.92295821],\n       [-0.62230274,  3.5622161 ,  0.00366482, ..., -0.56987189,\n        -0.5731713 , -1.08347268],\n       ...,\n       [ 0.89943174, -0.36597914,  0.00366482, ..., -0.56987189,\n        -0.5731713 ,  0.92295821],\n       [-0.62230274, -0.07855022,  1.39035319, ..., -0.56987189,\n         1.74467913, -1.08347268],\n       [-0.28299708,  0.87954618, -1.38302356, ...,  1.75478035,\n        -0.5731713 , -1.08347268]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = StandardScaler()\n",
    "x_train_scaled = scalar.fit_transform(x_train)\n",
    "\n",
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.55032881, -0.36597914,  1.0436811 , ...,  1.75478035,\n        -0.5731713 , -1.08347268],\n       [-1.31119605,  0.11306906, -1.03635146, ..., -0.56987189,\n        -0.5731713 , -1.08347268],\n       [ 0.57040807,  0.30468834,  1.0436811 , ..., -0.56987189,\n         1.74467913, -1.08347268],\n       ...,\n       [ 0.35448628,  0.11306906, -1.03635146, ..., -0.56987189,\n        -0.5731713 ,  0.92295821],\n       [ 0.42646021,  2.89154862,  1.73702529, ..., -0.56987189,\n        -0.5731713 ,  0.92295821],\n       [ 0.82745781,  0.97535582, -0.34300727, ...,  1.75478035,\n        -0.5731713 , -1.08347268]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled = scalar.transform(x_test)\n",
    "\n",
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training x: (11168, 12)\n",
      "Shape of training y: (11168,)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "print(\"Shape of training x:\", x_train_resampled.shape)\n",
    "print(\"Shape of training y:\", y_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "barplot = sns.countplot(x=y_train_resampled)\n",
    "barplot.set(\n",
    "    title=\"Exited Count\",\n",
    "    xlabel=\"Exited\",\n",
    "    ylabel=\"Count\",\n",
    "    xticklabels=[\"0 (No)\", \"1 (Yes)\"]\n",
    ")\n",
    "\n",
    "for p in barplot.patches:\n",
    "    percentage = p.get_height() / len(y_train_resampled)\n",
    "    _x = p.get_x() + 0.2\n",
    "    _y = p.get_height() + 60\n",
    "    barplot.annotate(f\"{percentage:.2%} ({p.get_height()})\", (_x, _y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training x: (11168, 12)\n",
      "Shape of training y: (11168,)\n",
      "Shape of testing x: (3000, 12)\n",
      "Shape of testing y: (3000,)\n"
     ]
    }
   ],
   "source": [
    "x_train_final = x_train_resampled\n",
    "y_train_final = y_train_resampled\n",
    "x_test_final = x_test_scaled\n",
    "y_test_final = y_test\n",
    "\n",
    "print(\"Shape of training x:\", x_train_final.shape)\n",
    "print(\"Shape of training y:\", y_train_final.shape)\n",
    "print(\"Shape of testing x:\", x_test_final.shape)\n",
    "print(\"Shape of testing y:\", y_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Model Implementation <a id=\"model_implementation\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.1 ? <a id=\"model_1\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1.1 Base Model <a id=\"base_model_1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1.2 Model Hyperparameter Tuning <a id=\"model_hyperparameter_tuning_1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1.3 Final Model <a id=\"final_model_1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.2 Artificial Neural Network <a id=\"model_2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2.1 Base Model <a id=\"base_model_2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(200, 200),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-06,\n",
    "    max_iter=50,\n",
    "    random_state=8\n",
    ")\n",
    "ann_model.fit(x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_accuracy = ann_model.score(x_test_final, y_test_final)\n",
    "\n",
    "print(f\"ANN accuracy: {ann_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ann_train_accuracy = ann_model.score(x_train_final, y_train_final)\n",
    "\n",
    "print(f\"ANN training accuracy: {ann_train_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = ann_model.predict(x_test_final)\n",
    "\n",
    "confusion_matrix(y_test_final, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_final, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2.2 Model Hyperparameter Tuning <a id=\"model_hyperparameter_tuning_2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN training accuracy: 81.96%\n",
      "ANN accuracy: 79.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ann_test_model = MLPClassifier(\n",
    "    hidden_layer_sizes=100,\n",
    "    activation=\"logistic\",\n",
    "    solver=\"lbfgs\",\n",
    "    alpha=0.001,\n",
    "    max_iter=50,\n",
    "    random_state=0\n",
    ")\n",
    "ann_test_model.fit(x_train_final, y_train_final)\n",
    "\n",
    "ann_train_accuracy = ann_test_model.score(x_train_final, y_train_final)\n",
    "print(f\"ANN training accuracy: {ann_train_accuracy:.2%}\")\n",
    "\n",
    "ann_test_accuracy = ann_test_model.score(x_test_final, y_test_final)\n",
    "print(f\"ANN accuracy: {ann_test_accuracy:.2%}\")\n",
    "# 100 -> 81.96, 79.77\n",
    "# 200 -> 52, 77\n",
    "# (150, 100) -> 50, 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Best ANN model training accuracy : 79.60%\n",
    "# Best ANN model test accuracy : 79.75%\n",
    "# {\n",
    "#     'activation': 'relu',\n",
    "#     'alpha': 0.0001,\n",
    "#     'hidden_layer_sizes': 100, 50, 200, (100, 100), (200, 100), (100, 50),\n",
    "#     'max_iter': 200,\n",
    "#     'random_state': 0,\n",
    "#     'solver': 'lbfgs'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [\n",
    "        50, 100, 200, (100, 50), (100, 100)\n",
    "    ],\n",
    "    \"activation\": [\"relu\"],\n",
    "    \"solver\": [\"adam\"],\n",
    "    \"alpha\": [1e-03],\n",
    "    \"max_iter\": [100],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "ann_cv_model1 = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    verbose=1\n",
    ")\n",
    "ann_cv_model1.fit(x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN model training accuracy : 87.10%\n",
      "Best ANN model test accuracy : 80.50%\n"
     ]
    }
   ],
   "source": [
    "ann_cv_train_accuracy1 = ann_cv_model1.best_score_\n",
    "ann_cv_accuracy1 = ann_cv_model1.score(x_test_final, y_test_final)\n",
    "\n",
    "print(f\"Best ANN model training accuracy : {ann_cv_train_accuracy1:.2%}\")\n",
    "print(f\"Best ANN model test accuracy : {ann_cv_accuracy1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN parameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best ANN parameters: {ann_cv_model1.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [53]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m ann_cv_results1 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(ann_cv_model1\u001B[38;5;241m.\u001B[39mcv_results_)\n\u001B[0;32m      2\u001B[0m ann_cv_results1\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m\"\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mann_cv_results1\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean_test_score\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparams\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "ann_cv_results1 = pd.DataFrame(ann_cv_model1.cv_results_)\n",
    "ann_cv_results1.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "ann_cv_results1[[\"mean_test_score\", \"params\"]].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tuning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [300, (100, 100), (200, 100)],\n",
       "                         &#x27;max_iter&#x27;: [100], &#x27;random_state&#x27;: [0],\n",
       "                         &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [300, (100, 100), (200, 100)],\n",
       "                         &#x27;max_iter&#x27;: [100], &#x27;random_state&#x27;: [0],\n",
       "                         &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['relu'], 'alpha': [0.001],\n",
       "                         'hidden_layer_sizes': [300, (100, 100), (200, 100)],\n",
       "                         'max_iter': [100], 'random_state': [0],\n",
       "                         'solver': ['adam']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [\n",
    "        300, (100, 100), (200, 100)\n",
    "    ],\n",
    "    \"activation\": [\"relu\"],\n",
    "    \"solver\": [\"adam\"],\n",
    "    \"alpha\": [1e-03],\n",
    "    \"max_iter\": [100],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "ann_cv_model2 = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    verbose=1\n",
    ")\n",
    "ann_cv_model2.fit(x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN model training accuracy : 88.17%\n",
      "Best ANN model test accuracy : 80.33%\n"
     ]
    }
   ],
   "source": [
    "ann_cv_train_accuracy2 = ann_cv_model2.best_score_\n",
    "ann_cv_accuracy2 = ann_cv_model2.score(x_test_final, y_test_final)\n",
    "\n",
    "print(f\"Best ANN model training accuracy : {ann_cv_train_accuracy2:.2%}\")\n",
    "print(f\"Best ANN model test accuracy : {ann_cv_accuracy2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN parameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best ANN parameters: {ann_cv_model2.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8817185531105206,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.8709734867361515,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.8407969735324411,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 300, 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_cv_results2 = pd.DataFrame(ann_cv_model2.cv_results_)\n",
    "ann_cv_results2.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "ann_cv_results2[[\"mean_test_score\", \"params\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tuning 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;logistic&#x27;], &#x27;alpha&#x27;: [0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(200, 100)], &#x27;max_iter&#x27;: [100],\n",
       "                         &#x27;random_state&#x27;: [0],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;logistic&#x27;], &#x27;alpha&#x27;: [0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(200, 100)], &#x27;max_iter&#x27;: [100],\n",
       "                         &#x27;random_state&#x27;: [0],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['relu', 'logistic'], 'alpha': [0.001],\n",
       "                         'hidden_layer_sizes': [(200, 100)], 'max_iter': [100],\n",
       "                         'random_state': [0],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(200, 100)],\n",
    "    \"activation\": [\"relu\", \"logistic\"],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"alpha\": [1e-03],\n",
    "    \"max_iter\": [100],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "ann_cv_model3 = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    verbose=1\n",
    ")\n",
    "ann_cv_model3.fit(x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN model training accuracy : 88.17%\n",
      "Best ANN model test accuracy : 80.33%\n"
     ]
    }
   ],
   "source": [
    "ann_cv_train_accuracy3 = ann_cv_model3.best_score_\n",
    "ann_cv_accuracy3 = ann_cv_model3.score(x_test_final, y_test_final)\n",
    "\n",
    "print(f\"Best ANN model training accuracy : {ann_cv_train_accuracy3:.2%}\")\n",
    "print(f\"Best ANN model test accuracy : {ann_cv_accuracy3:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN parameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best ANN parameters: {ann_cv_model3.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8817185531105206,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.872585066278148,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'lbfgs'}],\n",
       "       [0.7870697974269735,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'sgd'}],\n",
       "       [0.7856369882702733,\n",
       "        {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.785281291733303,\n",
       "        {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'lbfgs'}],\n",
       "       [0.6818575121047877,\n",
       "        {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'sgd'}]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_cv_results3 = pd.DataFrame(ann_cv_model3.cv_results_)\n",
    "ann_cv_results3.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "ann_cv_results3[[\"mean_test_score\", \"params\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tuning 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001, 0.01],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(200, 100)],\n",
       "                         &#x27;max_iter&#x27;: [100, 200], &#x27;random_state&#x27;: [0],\n",
       "                         &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001, 0.01],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(200, 100)],\n",
       "                         &#x27;max_iter&#x27;: [100, 200], &#x27;random_state&#x27;: [0],\n",
       "                         &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['relu'], 'alpha': [0.001, 0.01],\n",
       "                         'hidden_layer_sizes': [(200, 100)],\n",
       "                         'max_iter': [100, 200], 'random_state': [0],\n",
       "                         'solver': ['adam']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(200, 100)],\n",
    "    \"activation\": [\"relu\"],\n",
    "    \"solver\": [\"adam\"],\n",
    "    \"alpha\": [1e-03, 0.01],\n",
    "    \"max_iter\": [100, 200],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "ann_cv_model4 = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    verbose=2\n",
    ")\n",
    "ann_cv_model4.fit(x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN model training accuracy : 89.97%\n",
      "Best ANN model test accuracy : 65.40%\n"
     ]
    }
   ],
   "source": [
    "ann_cv_train_accuracy4 = ann_cv_model4.best_score_\n",
    "ann_cv_accuracy4 = ann_cv_model4.score(x_test_final, y_test_final)\n",
    "\n",
    "print(f\"Best ANN model training accuracy : {ann_cv_train_accuracy4:.2%}\")\n",
    "print(f\"Best ANN model test accuracy : {ann_cv_accuracy4:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN parameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 0, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best ANN parameters: {ann_cv_model4.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8997162285743153,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.887536308349447,\n",
       "        {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.8817185531105206,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.8806440865651188,\n",
       "        {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (200, 100), 'max_iter': 100, 'random_state': 0, 'solver': 'adam'}]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_cv_results4 = pd.DataFrame(ann_cv_model4.cv_results_)\n",
    "ann_cv_results4.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "ann_cv_results4[[\"mean_test_score\", \"params\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tuning 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Choong Man Shun\\.virtualenvs\\odl-txaD7ivL-py3.10\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(200, 100)], &#x27;max_iter&#x27;: [200],\n",
       "                         &#x27;random_state&#x27;: [0, 1, 2, 3, 4], &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;], &#x27;alpha&#x27;: [0.001],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(200, 100)], &#x27;max_iter&#x27;: [200],\n",
       "                         &#x27;random_state&#x27;: [0, 1, 2, 3, 4], &#x27;solver&#x27;: [&#x27;adam&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['relu'], 'alpha': [0.001],\n",
       "                         'hidden_layer_sizes': [(200, 100)], 'max_iter': [200],\n",
       "                         'random_state': [0, 1, 2, 3, 4], 'solver': ['adam']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(200, 100)],\n",
    "    \"activation\": [\"relu\"],\n",
    "    \"solver\": [\"adam\"],\n",
    "    \"alpha\": [1e-03],\n",
    "    \"max_iter\": [200],\n",
    "    \"random_state\": [0, 1, 2, 3, 4]\n",
    "}\n",
    "ann_cv_model5 = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    verbose=1\n",
    ")\n",
    "ann_cv_model5.fit(x_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN model training accuracy : 90.06%\n",
      "Best ANN model test accuracy : 80.27%\n"
     ]
    }
   ],
   "source": [
    "ann_cv_train_accuracy5 = ann_cv_model5.best_score_\n",
    "ann_cv_accuracy5 = ann_cv_model5.score(x_test_final, y_test_final)\n",
    "\n",
    "print(f\"Best ANN model training accuracy : {ann_cv_train_accuracy5:.2%}\")\n",
    "print(f\"Best ANN model test accuracy : {ann_cv_accuracy5:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN parameters: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 2, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best ANN parameters: {ann_cv_model5.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9006116440901734,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 2, 'solver': 'adam'}],\n",
       "       [0.8997162285743153,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 0, 'solver': 'adam'}],\n",
       "       [0.8969405366960395,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 3, 'solver': 'adam'}],\n",
       "       [0.8969402159597571,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 4, 'solver': 'adam'}],\n",
       "       [0.8961346466949529,\n",
       "        {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (200, 100), 'max_iter': 200, 'random_state': 1, 'solver': 'adam'}]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_cv_results5 = pd.DataFrame(ann_cv_model5.cv_results_)\n",
    "ann_cv_results5.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "\n",
    "ann_cv_results5[[\"mean_test_score\", \"params\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2.3 Final Model <a id=\"final_model_2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.3 Deep Neural Network (DNN) <a id=\"model_3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.3.1 Base Model <a id=\"base_model_3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 14        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251\n",
      "Trainable params: 251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(\n",
    "    Dense(\n",
    "        units=12,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"uniform\",\n",
    "        input_shape=(x_train_final.shape[1],)\n",
    "    )\n",
    ")\n",
    "dnn_model.add(\n",
    "    Dense(units=6, activation=\"relu\", kernel_initializer=\"uniform\")\n",
    ")\n",
    "dnn_model.add(\n",
    "    Dense(units=2, activation=\"relu\", kernel_initializer=\"uniform\")\n",
    ")\n",
    "dnn_model.add(\n",
    "    Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")\n",
    ")\n",
    "dnn_model.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 3s 2ms/step - loss: 0.6476 - accuracy: 0.6526 - val_loss: 0.7180 - val_accuracy: 0.6560\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5820 - accuracy: 0.7412 - val_loss: 0.6362 - val_accuracy: 0.7237\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7592 - val_loss: 0.5921 - val_accuracy: 0.7473\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7688 - val_loss: 0.5513 - val_accuracy: 0.7683\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4940 - accuracy: 0.7727 - val_loss: 0.5254 - val_accuracy: 0.7787\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7768 - val_loss: 0.5530 - val_accuracy: 0.7510\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4754 - accuracy: 0.7780 - val_loss: 0.5067 - val_accuracy: 0.7820\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4704 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7807\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.7813 - val_loss: 0.4932 - val_accuracy: 0.7813\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7826 - val_loss: 0.4847 - val_accuracy: 0.7860\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.7837 - val_loss: 0.4898 - val_accuracy: 0.7740\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4788 - val_accuracy: 0.7857\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.7835 - val_loss: 0.4540 - val_accuracy: 0.7987\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7825 - val_loss: 0.4757 - val_accuracy: 0.7843\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4541 - accuracy: 0.7850 - val_loss: 0.4504 - val_accuracy: 0.8007\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.7835 - val_loss: 0.4692 - val_accuracy: 0.7857\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.7838 - val_loss: 0.4564 - val_accuracy: 0.7933\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.7854 - val_loss: 0.4859 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.7856 - val_loss: 0.4844 - val_accuracy: 0.7757\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.7879 - val_loss: 0.4719 - val_accuracy: 0.7820\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.7867 - val_loss: 0.4579 - val_accuracy: 0.7913\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.4568 - val_accuracy: 0.7953\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.7855 - val_loss: 0.4717 - val_accuracy: 0.7807\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.7878 - val_loss: 0.4470 - val_accuracy: 0.7983\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.7873 - val_loss: 0.4554 - val_accuracy: 0.7940\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.7861 - val_loss: 0.4706 - val_accuracy: 0.7843\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.7873 - val_loss: 0.4899 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.7871 - val_loss: 0.4917 - val_accuracy: 0.7690\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.7867 - val_loss: 0.4486 - val_accuracy: 0.7980\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.7858 - val_loss: 0.4735 - val_accuracy: 0.7787\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7896 - val_loss: 0.4572 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.7890 - val_loss: 0.4432 - val_accuracy: 0.8013\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7871 - val_loss: 0.4713 - val_accuracy: 0.7827\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.7881 - val_loss: 0.4651 - val_accuracy: 0.7913\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.7871 - val_loss: 0.4696 - val_accuracy: 0.7847\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4437 - accuracy: 0.7878 - val_loss: 0.4679 - val_accuracy: 0.7863\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.7864 - val_loss: 0.4838 - val_accuracy: 0.7747\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.7879 - val_loss: 0.4557 - val_accuracy: 0.7950\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.7897 - val_loss: 0.4620 - val_accuracy: 0.7923\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.7891 - val_loss: 0.4566 - val_accuracy: 0.7930\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.7858 - val_loss: 0.4401 - val_accuracy: 0.8007\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.7881 - val_loss: 0.4788 - val_accuracy: 0.7770\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4427 - accuracy: 0.7888 - val_loss: 0.4621 - val_accuracy: 0.7863\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.7900 - val_loss: 0.4747 - val_accuracy: 0.7823\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.7898 - val_loss: 0.5006 - val_accuracy: 0.7667\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.7901 - val_loss: 0.4467 - val_accuracy: 0.7907\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4423 - accuracy: 0.7885 - val_loss: 0.5127 - val_accuracy: 0.7640\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.7904 - val_loss: 0.4533 - val_accuracy: 0.7920\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.7896 - val_loss: 0.4587 - val_accuracy: 0.7900\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.7912 - val_loss: 0.4852 - val_accuracy: 0.7727\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.7896 - val_loss: 0.4726 - val_accuracy: 0.7853\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.7894 - val_loss: 0.4643 - val_accuracy: 0.7833\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.7889 - val_loss: 0.4683 - val_accuracy: 0.7843\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.7922 - val_loss: 0.4913 - val_accuracy: 0.7717\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.7922 - val_loss: 0.4604 - val_accuracy: 0.7933\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4396 - accuracy: 0.7906 - val_loss: 0.4134 - val_accuracy: 0.8160\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.7918 - val_loss: 0.4588 - val_accuracy: 0.7927\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4406 - accuracy: 0.7914 - val_loss: 0.4587 - val_accuracy: 0.7917\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.7890 - val_loss: 0.4575 - val_accuracy: 0.7933\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4400 - accuracy: 0.7909 - val_loss: 0.4253 - val_accuracy: 0.8140\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.7913 - val_loss: 0.4438 - val_accuracy: 0.8010\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.7930 - val_loss: 0.4636 - val_accuracy: 0.7933\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4398 - accuracy: 0.7922 - val_loss: 0.4361 - val_accuracy: 0.8040\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.7910 - val_loss: 0.4711 - val_accuracy: 0.7853\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7918 - val_loss: 0.5003 - val_accuracy: 0.7697\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7925 - val_loss: 0.4542 - val_accuracy: 0.7967\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.7923 - val_loss: 0.4734 - val_accuracy: 0.7860\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.7931 - val_loss: 0.4904 - val_accuracy: 0.7753\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7920 - val_loss: 0.4769 - val_accuracy: 0.7813\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.7922 - val_loss: 0.5004 - val_accuracy: 0.7703\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7927 - val_loss: 0.4636 - val_accuracy: 0.7893\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.7920 - val_loss: 0.4642 - val_accuracy: 0.7877\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4384 - accuracy: 0.7925 - val_loss: 0.4967 - val_accuracy: 0.7727\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4386 - accuracy: 0.7922 - val_loss: 0.4484 - val_accuracy: 0.7983\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.7907 - val_loss: 0.4319 - val_accuracy: 0.8057\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.7918 - val_loss: 0.4640 - val_accuracy: 0.7863\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7924 - val_loss: 0.4524 - val_accuracy: 0.7983\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.7916 - val_loss: 0.4644 - val_accuracy: 0.7897\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.7907 - val_loss: 0.4358 - val_accuracy: 0.8023\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4385 - accuracy: 0.7924 - val_loss: 0.4517 - val_accuracy: 0.8013\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4369 - accuracy: 0.7930 - val_loss: 0.4322 - val_accuracy: 0.8083\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7925 - val_loss: 0.4535 - val_accuracy: 0.7983\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4375 - accuracy: 0.7924 - val_loss: 0.4546 - val_accuracy: 0.7990\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4380 - accuracy: 0.7946 - val_loss: 0.4775 - val_accuracy: 0.7863\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.7961 - val_loss: 0.4729 - val_accuracy: 0.7823\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7931 - val_loss: 0.4832 - val_accuracy: 0.7837\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.7944 - val_loss: 0.4512 - val_accuracy: 0.7960\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.7949 - val_loss: 0.4531 - val_accuracy: 0.7970\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.7936 - val_loss: 0.4505 - val_accuracy: 0.7963\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.7924 - val_loss: 0.4499 - val_accuracy: 0.7957\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.7906 - val_loss: 0.4970 - val_accuracy: 0.7777\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.7940 - val_loss: 0.4592 - val_accuracy: 0.7947\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7935 - val_loss: 0.4311 - val_accuracy: 0.8117\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.7921 - val_loss: 0.4385 - val_accuracy: 0.8037\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.7946 - val_loss: 0.4736 - val_accuracy: 0.7847\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.7940 - val_loss: 0.4653 - val_accuracy: 0.7937\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.7956 - val_loss: 0.4667 - val_accuracy: 0.7900\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7937 - val_loss: 0.4726 - val_accuracy: 0.7833\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.7937 - val_loss: 0.4455 - val_accuracy: 0.7970\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.7929 - val_loss: 0.4333 - val_accuracy: 0.8053\n"
     ]
    }
   ],
   "source": [
    "dnn_history = dnn_model.fit(\n",
    "    x_train_final, y_train_final, epochs=100, validation_data=(x_test_final, y_test_final)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4332866966724396, 0.8053333163261414]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(x_test_final, y_test_final)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.3.2 Model Hyperparameter Tuning <a id=\"model_hyperparameter_tuning_3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model1 = Sequential()\n",
    "dnn_model1.add(\n",
    "    Dense(\n",
    "        units=6,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"uniform\",  # \"normal\"\n",
    "        input_shape=(x_train_final.shape[1],)\n",
    "    )\n",
    ")\n",
    "dnn_model1.add(\n",
    "    Dense(\n",
    "        units=6, activation=\"relu\", kernel_initializer=\"uniform\"  # \"normal\"\n",
    "    )\n",
    ")\n",
    "dnn_model1.add(\n",
    "    Dense(\n",
    "        units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\"  # \"normal\"\n",
    "    )\n",
    ")\n",
    "dnn_model1.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "dnn_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 3s 7ms/step - loss: 0.6451 - accuracy: 0.6537 - val_loss: 0.6394 - val_accuracy: 0.6977\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7380 - val_loss: 0.5708 - val_accuracy: 0.7260\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5116 - accuracy: 0.7559 - val_loss: 0.5144 - val_accuracy: 0.7493\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7658 - val_loss: 0.4902 - val_accuracy: 0.7577\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7654 - val_loss: 0.5026 - val_accuracy: 0.7470\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7703 - val_loss: 0.4864 - val_accuracy: 0.7610\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7729 - val_loss: 0.4792 - val_accuracy: 0.7630\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7742 - val_loss: 0.4724 - val_accuracy: 0.7680\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.7763 - val_loss: 0.4691 - val_accuracy: 0.7723\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7739 - val_loss: 0.4606 - val_accuracy: 0.7753\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7755 - val_loss: 0.4806 - val_accuracy: 0.7580\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4598 - accuracy: 0.7782 - val_loss: 0.4894 - val_accuracy: 0.7537\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.7802 - val_loss: 0.4734 - val_accuracy: 0.7660\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4629 - val_accuracy: 0.7757\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7800 - val_loss: 0.4653 - val_accuracy: 0.7710\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7792 - val_loss: 0.4714 - val_accuracy: 0.7663\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4565 - accuracy: 0.7788 - val_loss: 0.4697 - val_accuracy: 0.7680\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7785 - val_loss: 0.4819 - val_accuracy: 0.7560\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7792 - val_loss: 0.4666 - val_accuracy: 0.7693\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7794 - val_loss: 0.4703 - val_accuracy: 0.7670\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7806 - val_loss: 0.4841 - val_accuracy: 0.7573\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.7783 - val_loss: 0.4505 - val_accuracy: 0.7830\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4542 - accuracy: 0.7817 - val_loss: 0.4863 - val_accuracy: 0.7563\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4536 - accuracy: 0.7808 - val_loss: 0.4596 - val_accuracy: 0.7813\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7821 - val_loss: 0.4674 - val_accuracy: 0.7707\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4532 - accuracy: 0.7823 - val_loss: 0.4899 - val_accuracy: 0.7517\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7798 - val_loss: 0.4688 - val_accuracy: 0.7717\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4533 - accuracy: 0.7802 - val_loss: 0.4844 - val_accuracy: 0.7597\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.7818 - val_loss: 0.4474 - val_accuracy: 0.7863\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 4ms/step - loss: 0.4528 - accuracy: 0.7806 - val_loss: 0.4412 - val_accuracy: 0.7927\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.7838 - val_loss: 0.4592 - val_accuracy: 0.7763\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.7829 - val_loss: 0.4583 - val_accuracy: 0.7753\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7818 - val_loss: 0.4594 - val_accuracy: 0.7793\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4527 - accuracy: 0.7835 - val_loss: 0.4487 - val_accuracy: 0.7847\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7835 - val_loss: 0.5081 - val_accuracy: 0.7417\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7841 - val_loss: 0.4890 - val_accuracy: 0.7553\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4528 - accuracy: 0.7805 - val_loss: 0.4757 - val_accuracy: 0.7650\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7844 - val_loss: 0.4597 - val_accuracy: 0.7793\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7825 - val_loss: 0.4681 - val_accuracy: 0.7713\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7553\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.4641 - val_accuracy: 0.7720\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.7809 - val_loss: 0.4608 - val_accuracy: 0.7757\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4518 - accuracy: 0.7814 - val_loss: 0.4742 - val_accuracy: 0.7700\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4515 - accuracy: 0.7831 - val_loss: 0.4671 - val_accuracy: 0.7727\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4512 - accuracy: 0.7818 - val_loss: 0.4369 - val_accuracy: 0.7933\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4509 - accuracy: 0.7811 - val_loss: 0.4717 - val_accuracy: 0.7687\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7840 - val_loss: 0.4735 - val_accuracy: 0.7673\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7821 - val_loss: 0.4517 - val_accuracy: 0.7857\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4513 - accuracy: 0.7815 - val_loss: 0.4588 - val_accuracy: 0.7817\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7818 - val_loss: 0.4628 - val_accuracy: 0.7757\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7810 - val_loss: 0.4595 - val_accuracy: 0.7863\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7815 - val_loss: 0.5005 - val_accuracy: 0.7517\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7837 - val_loss: 0.4655 - val_accuracy: 0.7757\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.7833 - val_loss: 0.4565 - val_accuracy: 0.7817\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7815 - val_loss: 0.4625 - val_accuracy: 0.7770\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4505 - accuracy: 0.7821 - val_loss: 0.4781 - val_accuracy: 0.7720\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7802 - val_loss: 0.4798 - val_accuracy: 0.7670\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4498 - accuracy: 0.7832 - val_loss: 0.4499 - val_accuracy: 0.7890\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7824 - val_loss: 0.4836 - val_accuracy: 0.7617\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4496 - accuracy: 0.7814 - val_loss: 0.4700 - val_accuracy: 0.7773\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7844 - val_loss: 0.4611 - val_accuracy: 0.7833\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7838 - val_loss: 0.4611 - val_accuracy: 0.7797\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7838 - val_loss: 0.4686 - val_accuracy: 0.7720\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4499 - accuracy: 0.7837 - val_loss: 0.4865 - val_accuracy: 0.7647\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7822 - val_loss: 0.4738 - val_accuracy: 0.7740\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4498 - accuracy: 0.7838 - val_loss: 0.4603 - val_accuracy: 0.7840\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7828 - val_loss: 0.4727 - val_accuracy: 0.7733\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7815 - val_loss: 0.4601 - val_accuracy: 0.7817\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7587\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7835 - val_loss: 0.4460 - val_accuracy: 0.7943\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7836 - val_loss: 0.4607 - val_accuracy: 0.7810\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7827 - val_loss: 0.4789 - val_accuracy: 0.7670\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7841 - val_loss: 0.4609 - val_accuracy: 0.7770\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7812 - val_loss: 0.4786 - val_accuracy: 0.7753\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4490 - accuracy: 0.7853 - val_loss: 0.4852 - val_accuracy: 0.7633\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7825 - val_loss: 0.4558 - val_accuracy: 0.7860\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7837 - val_loss: 0.4443 - val_accuracy: 0.7923\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7851 - val_loss: 0.4510 - val_accuracy: 0.7880\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7810 - val_loss: 0.5039 - val_accuracy: 0.7557\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4490 - accuracy: 0.7821 - val_loss: 0.4513 - val_accuracy: 0.7893\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7832 - val_loss: 0.4472 - val_accuracy: 0.7923\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7827 - val_loss: 0.4518 - val_accuracy: 0.7873\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4484 - accuracy: 0.7826 - val_loss: 0.4521 - val_accuracy: 0.7890\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7843 - val_loss: 0.4656 - val_accuracy: 0.7783\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.4823 - val_accuracy: 0.7650\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7828 - val_loss: 0.4718 - val_accuracy: 0.7750\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7834 - val_loss: 0.4767 - val_accuracy: 0.7727\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7828 - val_loss: 0.4727 - val_accuracy: 0.7760\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4483 - accuracy: 0.7821 - val_loss: 0.4485 - val_accuracy: 0.7903\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7832 - val_loss: 0.4568 - val_accuracy: 0.7850\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7842 - val_loss: 0.4686 - val_accuracy: 0.7733\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7812 - val_loss: 0.4755 - val_accuracy: 0.7757\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4485 - accuracy: 0.7855 - val_loss: 0.4787 - val_accuracy: 0.7730\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4484 - accuracy: 0.7826 - val_loss: 0.4689 - val_accuracy: 0.7777\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4485 - accuracy: 0.7825 - val_loss: 0.4592 - val_accuracy: 0.7837\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.7846 - val_loss: 0.4466 - val_accuracy: 0.7950\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4484 - accuracy: 0.7845 - val_loss: 0.4739 - val_accuracy: 0.7737\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7814 - val_loss: 0.4637 - val_accuracy: 0.7800\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4484 - accuracy: 0.7835 - val_loss: 0.4515 - val_accuracy: 0.7867\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4483 - accuracy: 0.7840 - val_loss: 0.4787 - val_accuracy: 0.7713\n"
     ]
    }
   ],
   "source": [
    "dnn_history1 = dnn_model1.fit(\n",
    "    x_train_final, y_train_final, epochs=100, validation_data=(x_test_final, y_test_final)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127\n",
      "Trainable params: 127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model2 = Sequential()\n",
    "dnn_model2.add(\n",
    "    Dense(\n",
    "        units=6,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"normal\",\n",
    "        input_shape=(x_train_final.shape[1],)\n",
    "    )\n",
    ")\n",
    "dnn_model2.add(\n",
    "    Dense(\n",
    "        units=6, activation=\"relu\", kernel_initializer=\"normal\"\n",
    "    )\n",
    ")\n",
    "dnn_model2.add(\n",
    "    Dense(\n",
    "        units=1, activation=\"sigmoid\", kernel_initializer=\"normal\"\n",
    "    )\n",
    ")\n",
    "dnn_model2.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "dnn_model2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 2s 2ms/step - loss: 0.6363 - accuracy: 0.6716 - val_loss: 0.5519 - val_accuracy: 0.6973\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7305 - val_loss: 0.5698 - val_accuracy: 0.6983\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.5240 - accuracy: 0.7465 - val_loss: 0.5250 - val_accuracy: 0.7413\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7583 - val_loss: 0.5554 - val_accuracy: 0.7173\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4896 - accuracy: 0.7667 - val_loss: 0.5081 - val_accuracy: 0.7433\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7684 - val_loss: 0.5079 - val_accuracy: 0.7457\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4714 - accuracy: 0.7715 - val_loss: 0.4917 - val_accuracy: 0.7553\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4680 - accuracy: 0.7727 - val_loss: 0.4893 - val_accuracy: 0.7577\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7753 - val_loss: 0.4894 - val_accuracy: 0.7553\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7757 - val_loss: 0.4889 - val_accuracy: 0.7547\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4623 - accuracy: 0.7753 - val_loss: 0.4621 - val_accuracy: 0.7713\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.7780 - val_loss: 0.5079 - val_accuracy: 0.7390\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7779 - val_loss: 0.4823 - val_accuracy: 0.7540\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7786 - val_loss: 0.4715 - val_accuracy: 0.7643\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7799 - val_loss: 0.4769 - val_accuracy: 0.7623\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7811 - val_loss: 0.4746 - val_accuracy: 0.7630\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7773 - val_loss: 0.4677 - val_accuracy: 0.7650\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7815 - val_loss: 0.4633 - val_accuracy: 0.7717\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7800 - val_loss: 0.4906 - val_accuracy: 0.7503\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7802 - val_loss: 0.4683 - val_accuracy: 0.7653\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4548 - accuracy: 0.7810 - val_loss: 0.4666 - val_accuracy: 0.7693\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4542 - accuracy: 0.7825 - val_loss: 0.4371 - val_accuracy: 0.7920\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4541 - accuracy: 0.7820 - val_loss: 0.4657 - val_accuracy: 0.7710\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.7805 - val_loss: 0.4569 - val_accuracy: 0.7803\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7840 - val_loss: 0.5104 - val_accuracy: 0.7383\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7837 - val_loss: 0.4761 - val_accuracy: 0.7640\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7825 - val_loss: 0.4544 - val_accuracy: 0.7797\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4518 - accuracy: 0.7835 - val_loss: 0.4766 - val_accuracy: 0.7663\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.4754 - val_accuracy: 0.7620\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7853 - val_loss: 0.4825 - val_accuracy: 0.7583\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7861 - val_loss: 0.4711 - val_accuracy: 0.7650\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7875 - val_loss: 0.4434 - val_accuracy: 0.7840\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7856 - val_loss: 0.4602 - val_accuracy: 0.7700\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7898 - val_loss: 0.4872 - val_accuracy: 0.7570\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7873 - val_loss: 0.4819 - val_accuracy: 0.7587\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7898 - val_loss: 0.4768 - val_accuracy: 0.7633\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4473 - accuracy: 0.7881 - val_loss: 0.4682 - val_accuracy: 0.7693\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.7889 - val_loss: 0.4939 - val_accuracy: 0.7540\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7907 - val_loss: 0.4711 - val_accuracy: 0.7673\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7893 - val_loss: 0.4571 - val_accuracy: 0.7743\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.7907 - val_loss: 0.4573 - val_accuracy: 0.7783\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.7878 - val_loss: 0.4571 - val_accuracy: 0.7790\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.4633 - val_accuracy: 0.7747\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4445 - accuracy: 0.7910 - val_loss: 0.4822 - val_accuracy: 0.7610\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7911 - val_loss: 0.4723 - val_accuracy: 0.7700\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7892 - val_loss: 0.4846 - val_accuracy: 0.7607\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.7915 - val_loss: 0.4641 - val_accuracy: 0.7743\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7892 - val_loss: 0.4799 - val_accuracy: 0.7613\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.7916 - val_loss: 0.4860 - val_accuracy: 0.7583\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.7915 - val_loss: 0.4561 - val_accuracy: 0.7803\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7898 - val_loss: 0.4584 - val_accuracy: 0.7810\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.7919 - val_loss: 0.4707 - val_accuracy: 0.7737\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.7921 - val_loss: 0.4844 - val_accuracy: 0.7680\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7907 - val_loss: 0.4725 - val_accuracy: 0.7720\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7923 - val_loss: 0.4899 - val_accuracy: 0.7620\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7915 - val_loss: 0.4721 - val_accuracy: 0.7687\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4428 - accuracy: 0.7917 - val_loss: 0.4750 - val_accuracy: 0.7720\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.7922 - val_loss: 0.4775 - val_accuracy: 0.7717\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.7915 - val_loss: 0.4906 - val_accuracy: 0.7647\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.7929 - val_loss: 0.5005 - val_accuracy: 0.7570\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.7910 - val_loss: 0.4626 - val_accuracy: 0.7813\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7898 - val_loss: 0.4820 - val_accuracy: 0.7667\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.7905 - val_loss: 0.4952 - val_accuracy: 0.7587\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7914 - val_loss: 0.4895 - val_accuracy: 0.7660\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7905 - val_loss: 0.4641 - val_accuracy: 0.7843\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7925 - val_loss: 0.4583 - val_accuracy: 0.7873\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7927 - val_loss: 0.4770 - val_accuracy: 0.7737\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.7916 - val_loss: 0.4842 - val_accuracy: 0.7727\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7916 - val_loss: 0.4706 - val_accuracy: 0.7793\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.7930 - val_loss: 0.4543 - val_accuracy: 0.7850\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7932 - val_loss: 0.4510 - val_accuracy: 0.7907\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4416 - accuracy: 0.7915 - val_loss: 0.4662 - val_accuracy: 0.7807\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4409 - accuracy: 0.7924 - val_loss: 0.4610 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4411 - accuracy: 0.7924 - val_loss: 0.4559 - val_accuracy: 0.7903\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7936 - val_loss: 0.4828 - val_accuracy: 0.7703\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7932 - val_loss: 0.4783 - val_accuracy: 0.7727\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7910 - val_loss: 0.4627 - val_accuracy: 0.7837\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4626 - val_accuracy: 0.7830\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7913 - val_loss: 0.4694 - val_accuracy: 0.7827\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7925 - val_loss: 0.4667 - val_accuracy: 0.7807\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7923 - val_loss: 0.4737 - val_accuracy: 0.7783\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7929 - val_loss: 0.4734 - val_accuracy: 0.7767\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7930 - val_loss: 0.4557 - val_accuracy: 0.7917\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7935 - val_loss: 0.4561 - val_accuracy: 0.7893\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7905 - val_loss: 0.4669 - val_accuracy: 0.7863\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4401 - accuracy: 0.7929 - val_loss: 0.4667 - val_accuracy: 0.7837\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4399 - accuracy: 0.7922 - val_loss: 0.4586 - val_accuracy: 0.7903\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.4694 - val_accuracy: 0.7773\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4397 - accuracy: 0.7905 - val_loss: 0.4820 - val_accuracy: 0.7727\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7954 - val_loss: 0.4553 - val_accuracy: 0.7920\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4396 - accuracy: 0.7932 - val_loss: 0.4457 - val_accuracy: 0.7943\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7959 - val_loss: 0.4726 - val_accuracy: 0.7833\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.7947 - val_loss: 0.4795 - val_accuracy: 0.7803\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.7927 - val_loss: 0.4498 - val_accuracy: 0.7910\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7936 - val_loss: 0.4660 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7931 - val_loss: 0.4682 - val_accuracy: 0.7847\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7933 - val_loss: 0.4358 - val_accuracy: 0.8007\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7926 - val_loss: 0.4483 - val_accuracy: 0.7917\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7928 - val_loss: 0.4754 - val_accuracy: 0.7793\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7923 - val_loss: 0.4681 - val_accuracy: 0.7820\n"
     ]
    }
   ],
   "source": [
    "dnn_history2 = dnn_model2.fit(\n",
    "    x_train_final, y_train_final, epochs=100, validation_data=(x_test_final, y_test_final)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model3 = Sequential()\n",
    "dnn_model3.add(\n",
    "    Dense(\n",
    "        units=6,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"normal\",\n",
    "        input_shape=(x_train_final.shape[1],)\n",
    "    )\n",
    ")\n",
    "dnn_model3.add(\n",
    "    Dense(units=6, activation=\"relu\", kernel_initializer=\"normal\")\n",
    ")\n",
    "dnn_model3.add(\n",
    "    Dense(units=3, activation=\"relu\", kernel_initializer=\"normal\")\n",
    ")\n",
    "dnn_model3.add(\n",
    "    Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"normal\")\n",
    ")\n",
    "dnn_model3.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "dnn_model3.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.6551 - accuracy: 0.6081 - val_loss: 0.5156 - val_accuracy: 0.7353\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5709 - accuracy: 0.7457 - val_loss: 0.4898 - val_accuracy: 0.7403\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7619 - val_loss: 0.4776 - val_accuracy: 0.7553\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7690 - val_loss: 0.4761 - val_accuracy: 0.7533\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.7761 - val_loss: 0.4711 - val_accuracy: 0.7660\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4941 - accuracy: 0.7772 - val_loss: 0.4938 - val_accuracy: 0.7463\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.7774 - val_loss: 0.4477 - val_accuracy: 0.7853\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4793 - accuracy: 0.7773 - val_loss: 0.4713 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4746 - accuracy: 0.7790 - val_loss: 0.5074 - val_accuracy: 0.7413\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7807 - val_loss: 0.4677 - val_accuracy: 0.7777\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7821 - val_loss: 0.4821 - val_accuracy: 0.7653\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7844 - val_loss: 0.4851 - val_accuracy: 0.7670\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7852 - val_loss: 0.4906 - val_accuracy: 0.7650\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4598 - accuracy: 0.7867 - val_loss: 0.4632 - val_accuracy: 0.7863\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7865 - val_loss: 0.4429 - val_accuracy: 0.7987\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.7867 - val_loss: 0.4725 - val_accuracy: 0.7787\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7878 - val_loss: 0.4680 - val_accuracy: 0.7837\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.7872 - val_loss: 0.4837 - val_accuracy: 0.7733\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7876 - val_loss: 0.4812 - val_accuracy: 0.7767\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.7888 - val_loss: 0.4795 - val_accuracy: 0.7770\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.7867 - val_loss: 0.4648 - val_accuracy: 0.7850\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.7884 - val_loss: 0.4594 - val_accuracy: 0.7890\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.7884 - val_loss: 0.4905 - val_accuracy: 0.7670\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.7905 - val_loss: 0.4838 - val_accuracy: 0.7730\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7890 - val_loss: 0.4652 - val_accuracy: 0.7833\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7898 - val_loss: 0.4929 - val_accuracy: 0.7687\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4486 - accuracy: 0.7886 - val_loss: 0.4866 - val_accuracy: 0.7727\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7907 - val_loss: 0.4947 - val_accuracy: 0.7663\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7896 - val_loss: 0.4721 - val_accuracy: 0.7820\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4468 - accuracy: 0.7897 - val_loss: 0.4652 - val_accuracy: 0.7870\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7909 - val_loss: 0.5049 - val_accuracy: 0.7650\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.7911 - val_loss: 0.4579 - val_accuracy: 0.7893\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7927 - val_loss: 0.4348 - val_accuracy: 0.8077\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.7911 - val_loss: 0.4560 - val_accuracy: 0.7903\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.7911 - val_loss: 0.4755 - val_accuracy: 0.7807\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4448 - accuracy: 0.7928 - val_loss: 0.4870 - val_accuracy: 0.7747\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.7911 - val_loss: 0.4345 - val_accuracy: 0.8037\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4447 - accuracy: 0.7907 - val_loss: 0.4711 - val_accuracy: 0.7883\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.7918 - val_loss: 0.4665 - val_accuracy: 0.7853\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7905 - val_loss: 0.4557 - val_accuracy: 0.7920\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.7921 - val_loss: 0.4628 - val_accuracy: 0.7903\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4428 - accuracy: 0.7901 - val_loss: 0.4692 - val_accuracy: 0.7840\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4424 - accuracy: 0.7924 - val_loss: 0.4509 - val_accuracy: 0.7950\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.7915 - val_loss: 0.4681 - val_accuracy: 0.7920\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.7906 - val_loss: 0.4740 - val_accuracy: 0.7840\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4418 - accuracy: 0.7932 - val_loss: 0.4804 - val_accuracy: 0.7817\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7919 - val_loss: 0.4861 - val_accuracy: 0.7750\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.7926 - val_loss: 0.4899 - val_accuracy: 0.7743\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4413 - accuracy: 0.7906 - val_loss: 0.4762 - val_accuracy: 0.7780\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4409 - accuracy: 0.7924 - val_loss: 0.4756 - val_accuracy: 0.7803\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.7907 - val_loss: 0.4697 - val_accuracy: 0.7870\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.7920 - val_loss: 0.4583 - val_accuracy: 0.7897\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.7910 - val_loss: 0.4613 - val_accuracy: 0.7920\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.7911 - val_loss: 0.4534 - val_accuracy: 0.7947\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.7927 - val_loss: 0.4668 - val_accuracy: 0.7843\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.7919 - val_loss: 0.4437 - val_accuracy: 0.8030\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.7919 - val_loss: 0.4538 - val_accuracy: 0.7950\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4388 - accuracy: 0.7930 - val_loss: 0.4779 - val_accuracy: 0.7817\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4383 - accuracy: 0.7906 - val_loss: 0.4986 - val_accuracy: 0.7683\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.7911 - val_loss: 0.4785 - val_accuracy: 0.7803\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7915 - val_loss: 0.4807 - val_accuracy: 0.7763\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7915 - val_loss: 0.4381 - val_accuracy: 0.8027\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4377 - accuracy: 0.7919 - val_loss: 0.4472 - val_accuracy: 0.7957\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4363 - accuracy: 0.7940 - val_loss: 0.4691 - val_accuracy: 0.7890\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7919 - val_loss: 0.4462 - val_accuracy: 0.8003\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4370 - accuracy: 0.7916 - val_loss: 0.4467 - val_accuracy: 0.7990\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4364 - accuracy: 0.7927 - val_loss: 0.4821 - val_accuracy: 0.7790\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4362 - accuracy: 0.7958 - val_loss: 0.4594 - val_accuracy: 0.7913\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7929 - val_loss: 0.4525 - val_accuracy: 0.7953\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4361 - accuracy: 0.7932 - val_loss: 0.4203 - val_accuracy: 0.8110\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7935 - val_loss: 0.4219 - val_accuracy: 0.8127\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7947 - val_loss: 0.4491 - val_accuracy: 0.7950\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7935 - val_loss: 0.4653 - val_accuracy: 0.7877\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7948 - val_loss: 0.4652 - val_accuracy: 0.7893\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7949 - val_loss: 0.4609 - val_accuracy: 0.7920\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7944 - val_loss: 0.4534 - val_accuracy: 0.7983\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7959 - val_loss: 0.4523 - val_accuracy: 0.7967\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.7959 - val_loss: 0.4494 - val_accuracy: 0.8010\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4351 - accuracy: 0.7945 - val_loss: 0.4437 - val_accuracy: 0.8007\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7921 - val_loss: 0.4298 - val_accuracy: 0.8090\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.7945 - val_loss: 0.4849 - val_accuracy: 0.7830\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7932 - val_loss: 0.4480 - val_accuracy: 0.8010\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7953 - val_loss: 0.4695 - val_accuracy: 0.7850\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7933 - val_loss: 0.4930 - val_accuracy: 0.7763\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7950 - val_loss: 0.4428 - val_accuracy: 0.8003\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7954 - val_loss: 0.4702 - val_accuracy: 0.7850\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7908 - val_loss: 0.4478 - val_accuracy: 0.8000\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4349 - accuracy: 0.7914 - val_loss: 0.4721 - val_accuracy: 0.7840\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7923 - val_loss: 0.4383 - val_accuracy: 0.8057\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7949 - val_loss: 0.4608 - val_accuracy: 0.7947\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.7928 - val_loss: 0.4648 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.7920 - val_loss: 0.4896 - val_accuracy: 0.7810\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7940 - val_loss: 0.4616 - val_accuracy: 0.7910\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4331 - accuracy: 0.7921 - val_loss: 0.4919 - val_accuracy: 0.7737\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7941 - val_loss: 0.4520 - val_accuracy: 0.7950\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7947 - val_loss: 0.4527 - val_accuracy: 0.7997\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7964 - val_loss: 0.4553 - val_accuracy: 0.7933\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7933 - val_loss: 0.4592 - val_accuracy: 0.7893\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4335 - accuracy: 0.7956 - val_loss: 0.4612 - val_accuracy: 0.7923\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 0.4339 - accuracy: 0.7940 - val_loss: 0.4622 - val_accuracy: 0.7913\n"
     ]
    }
   ],
   "source": [
    "dnn_history3 = dnn_model3.fit(\n",
    "    x_train_final, y_train_final, epochs=100, validation_data=(x_test_final, y_test_final)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 6)                 78        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6)                 0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6)                24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 3)                 21        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 3)                 0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 3)                12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 121\n",
      "Non-trainable params: 18\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model4 = Sequential()\n",
    "dnn_model4.add(\n",
    "    Dense(\n",
    "        units=6,\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"normal\",\n",
    "        input_shape=(x_train_final.shape[1],)\n",
    "    )\n",
    ")\n",
    "\n",
    "dnn_model4.add(Dropout(rate = 0.1))\n",
    "dnn_model4.add(BatchNormalization())\n",
    "\n",
    "dnn_model4.add(\n",
    "    Dense(units=3, activation=\"relu\", kernel_initializer=\"normal\")\n",
    ")\n",
    "\n",
    "dnn_model4.add(Dropout(rate = 0.1))\n",
    "dnn_model4.add(BatchNormalization())\n",
    "\n",
    "dnn_model4.add(\n",
    "    Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"normal\")\n",
    ")\n",
    "dnn_model4.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "dnn_model4.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 2s 3ms/step - loss: 0.6145 - accuracy: 0.6941 - val_loss: 0.5911 - val_accuracy: 0.7427\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7356 - val_loss: 0.4800 - val_accuracy: 0.7763\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7444 - val_loss: 0.4654 - val_accuracy: 0.7830\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7504 - val_loss: 0.4857 - val_accuracy: 0.7703\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7473 - val_loss: 0.4639 - val_accuracy: 0.7963\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7497 - val_loss: 0.4689 - val_accuracy: 0.7803\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7586 - val_loss: 0.4799 - val_accuracy: 0.7713\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7562 - val_loss: 0.4587 - val_accuracy: 0.7907\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.7531 - val_loss: 0.4755 - val_accuracy: 0.7797\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5075 - accuracy: 0.7530 - val_loss: 0.4729 - val_accuracy: 0.7750\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7590 - val_loss: 0.4659 - val_accuracy: 0.7730\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7562 - val_loss: 0.4842 - val_accuracy: 0.7710\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7565 - val_loss: 0.4556 - val_accuracy: 0.7943\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7513 - val_loss: 0.4697 - val_accuracy: 0.7780\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.7590 - val_loss: 0.4516 - val_accuracy: 0.7963\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4988 - accuracy: 0.7554 - val_loss: 0.4617 - val_accuracy: 0.7840\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7538 - val_loss: 0.4624 - val_accuracy: 0.7843\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5014 - accuracy: 0.7556 - val_loss: 0.4586 - val_accuracy: 0.7857\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7546 - val_loss: 0.4747 - val_accuracy: 0.7793\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.7573 - val_loss: 0.4690 - val_accuracy: 0.7783\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.7611 - val_loss: 0.4695 - val_accuracy: 0.7823\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7582 - val_loss: 0.4551 - val_accuracy: 0.7980\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.7583 - val_loss: 0.4635 - val_accuracy: 0.7830\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7613 - val_loss: 0.4738 - val_accuracy: 0.7800\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7559 - val_loss: 0.4680 - val_accuracy: 0.7773\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.7530 - val_loss: 0.4610 - val_accuracy: 0.7847\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.7613 - val_loss: 0.4745 - val_accuracy: 0.7820\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.7600 - val_loss: 0.4566 - val_accuracy: 0.7897\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7591 - val_loss: 0.4558 - val_accuracy: 0.7837\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7592 - val_loss: 0.4658 - val_accuracy: 0.7807\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5089 - accuracy: 0.7521 - val_loss: 0.4513 - val_accuracy: 0.7917\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4987 - accuracy: 0.7595 - val_loss: 0.4599 - val_accuracy: 0.7870\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7580 - val_loss: 0.4617 - val_accuracy: 0.7857\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7572 - val_loss: 0.4758 - val_accuracy: 0.7813\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7553 - val_loss: 0.4711 - val_accuracy: 0.7817\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4978 - accuracy: 0.7603 - val_loss: 0.4778 - val_accuracy: 0.7717\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7581 - val_loss: 0.4513 - val_accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7571 - val_loss: 0.4567 - val_accuracy: 0.7870\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7556 - val_loss: 0.4751 - val_accuracy: 0.7757\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7520 - val_loss: 0.4585 - val_accuracy: 0.7820\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.7601 - val_loss: 0.4710 - val_accuracy: 0.7780\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.7554 - val_loss: 0.4560 - val_accuracy: 0.7853\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7615 - val_loss: 0.4530 - val_accuracy: 0.7910\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7556 - val_loss: 0.4629 - val_accuracy: 0.7837\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7570 - val_loss: 0.4693 - val_accuracy: 0.7780\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.7573 - val_loss: 0.4630 - val_accuracy: 0.7753\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.4680 - val_accuracy: 0.7707\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4987 - accuracy: 0.7581 - val_loss: 0.4652 - val_accuracy: 0.7787\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.7614 - val_loss: 0.4776 - val_accuracy: 0.7730\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4957 - accuracy: 0.7651 - val_loss: 0.4480 - val_accuracy: 0.7910\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7571 - val_loss: 0.4555 - val_accuracy: 0.7827\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7609 - val_loss: 0.4550 - val_accuracy: 0.7797\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.7572 - val_loss: 0.4496 - val_accuracy: 0.7950\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7539 - val_loss: 0.4608 - val_accuracy: 0.7833\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7566 - val_loss: 0.4726 - val_accuracy: 0.7757\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.7563 - val_loss: 0.4754 - val_accuracy: 0.7710\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7570 - val_loss: 0.4700 - val_accuracy: 0.7757\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.7579 - val_loss: 0.4786 - val_accuracy: 0.7683\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7568 - val_loss: 0.4543 - val_accuracy: 0.7843\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7593 - val_loss: 0.4701 - val_accuracy: 0.7760\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.7545 - val_loss: 0.4689 - val_accuracy: 0.7773\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.7617 - val_loss: 0.4558 - val_accuracy: 0.7897\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.7514 - val_loss: 0.4539 - val_accuracy: 0.7913\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.7609 - val_loss: 0.4599 - val_accuracy: 0.7873\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7576 - val_loss: 0.4649 - val_accuracy: 0.7777\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7544 - val_loss: 0.4628 - val_accuracy: 0.7850\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7552 - val_loss: 0.4409 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.4647 - val_accuracy: 0.7820\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7602 - val_loss: 0.4654 - val_accuracy: 0.7773\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4984 - accuracy: 0.7586 - val_loss: 0.4639 - val_accuracy: 0.7797\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4984 - accuracy: 0.7600 - val_loss: 0.4748 - val_accuracy: 0.7710\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4979 - accuracy: 0.7616 - val_loss: 0.4653 - val_accuracy: 0.7770\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.7626 - val_loss: 0.4649 - val_accuracy: 0.7783\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7548 - val_loss: 0.4682 - val_accuracy: 0.7757\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7563 - val_loss: 0.4599 - val_accuracy: 0.7830\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7577 - val_loss: 0.4727 - val_accuracy: 0.7767\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7583 - val_loss: 0.4495 - val_accuracy: 0.7913\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7612 - val_loss: 0.4576 - val_accuracy: 0.7830\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5002 - accuracy: 0.7597 - val_loss: 0.4810 - val_accuracy: 0.7660\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7558 - val_loss: 0.4732 - val_accuracy: 0.7787\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.7566 - val_loss: 0.4522 - val_accuracy: 0.7957\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7612 - val_loss: 0.4731 - val_accuracy: 0.7797\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7599 - val_loss: 0.4660 - val_accuracy: 0.7807\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7560 - val_loss: 0.4600 - val_accuracy: 0.7910\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.7578 - val_loss: 0.4598 - val_accuracy: 0.7910\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.7609 - val_loss: 0.4717 - val_accuracy: 0.7807\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.7565 - val_loss: 0.4562 - val_accuracy: 0.7897\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7563 - val_loss: 0.4667 - val_accuracy: 0.7847\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7585 - val_loss: 0.4600 - val_accuracy: 0.7783\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7575 - val_loss: 0.4546 - val_accuracy: 0.7843\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5001 - accuracy: 0.7564 - val_loss: 0.4755 - val_accuracy: 0.7703\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.7606 - val_loss: 0.4619 - val_accuracy: 0.7840\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4970 - accuracy: 0.7613 - val_loss: 0.4702 - val_accuracy: 0.7823\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7538 - val_loss: 0.4536 - val_accuracy: 0.7913\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7561 - val_loss: 0.4594 - val_accuracy: 0.7917\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4971 - accuracy: 0.7637 - val_loss: 0.4707 - val_accuracy: 0.7800\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.7598 - val_loss: 0.4607 - val_accuracy: 0.7830\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.7583 - val_loss: 0.4722 - val_accuracy: 0.7760\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4962 - accuracy: 0.7580 - val_loss: 0.4703 - val_accuracy: 0.7807\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.7594 - val_loss: 0.4473 - val_accuracy: 0.7950\n"
     ]
    }
   ],
   "source": [
    "dnn_history4 = dnn_model4.fit(\n",
    "    x_train_final, y_train_final, epochs=100, validation_data=(x_test_final, y_test_final)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 5s 3ms/step - loss: 0.5836 - accuracy: 0.7103 - val_loss: 0.5744 - val_accuracy: 0.7417\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.5124 - accuracy: 0.7453 - val_loss: 0.4714 - val_accuracy: 0.7597\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7635 - val_loss: 0.5127 - val_accuracy: 0.7160\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4865 - accuracy: 0.7614 - val_loss: 0.4964 - val_accuracy: 0.7353\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7689 - val_loss: 0.4647 - val_accuracy: 0.7570\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.7667 - val_loss: 0.4695 - val_accuracy: 0.7633\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.7698 - val_loss: 0.4526 - val_accuracy: 0.7797\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7699 - val_loss: 0.4650 - val_accuracy: 0.7723\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.7722 - val_loss: 0.4845 - val_accuracy: 0.7563\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7731 - val_loss: 0.4414 - val_accuracy: 0.7920\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.7778 - val_loss: 0.4577 - val_accuracy: 0.7837\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.7761 - val_loss: 0.4616 - val_accuracy: 0.7740\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7772 - val_loss: 0.4440 - val_accuracy: 0.7907\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.7798 - val_loss: 0.4443 - val_accuracy: 0.7980\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7804 - val_loss: 0.4696 - val_accuracy: 0.7713\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7831 - val_loss: 0.4474 - val_accuracy: 0.7813\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.7819 - val_loss: 0.4452 - val_accuracy: 0.7897\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.7813 - val_loss: 0.4441 - val_accuracy: 0.7860\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4652 - accuracy: 0.7799 - val_loss: 0.4409 - val_accuracy: 0.7880\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7814 - val_loss: 0.4423 - val_accuracy: 0.7887\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7795 - val_loss: 0.4374 - val_accuracy: 0.7940\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.7864 - val_loss: 0.4560 - val_accuracy: 0.7767\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7826 - val_loss: 0.4720 - val_accuracy: 0.7690\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.7792 - val_loss: 0.4388 - val_accuracy: 0.7943\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7870 - val_loss: 0.4484 - val_accuracy: 0.7903\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7735 - val_loss: 0.4285 - val_accuracy: 0.7987\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7804 - val_loss: 0.4514 - val_accuracy: 0.7793\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.7833 - val_loss: 0.4494 - val_accuracy: 0.7830\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4677 - accuracy: 0.7794 - val_loss: 0.4566 - val_accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7828 - val_loss: 0.4365 - val_accuracy: 0.7930\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7862 - val_loss: 0.4402 - val_accuracy: 0.7887\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4470 - val_accuracy: 0.7833\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7829 - val_loss: 0.4480 - val_accuracy: 0.7847\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7831 - val_loss: 0.4563 - val_accuracy: 0.7793\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7786 - val_loss: 0.4379 - val_accuracy: 0.7963\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7835 - val_loss: 0.4510 - val_accuracy: 0.7893\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.7767 - val_loss: 0.4758 - val_accuracy: 0.7777\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4602 - accuracy: 0.7835 - val_loss: 0.4503 - val_accuracy: 0.7870\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.7800 - val_loss: 0.4239 - val_accuracy: 0.8033\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.7849 - val_loss: 0.4368 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7807 - val_loss: 0.4544 - val_accuracy: 0.7767\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.7805 - val_loss: 0.4389 - val_accuracy: 0.7990\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.7812 - val_loss: 0.4466 - val_accuracy: 0.7927\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.7835 - val_loss: 0.4549 - val_accuracy: 0.7847\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.7839 - val_loss: 0.4318 - val_accuracy: 0.8037\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4244 - val_accuracy: 0.8023\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.7810 - val_loss: 0.4553 - val_accuracy: 0.7773\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4258 - val_accuracy: 0.8060\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7804 - val_loss: 0.4292 - val_accuracy: 0.8080\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.4444 - val_accuracy: 0.7907\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.7821 - val_loss: 0.4382 - val_accuracy: 0.7967\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7785 - val_loss: 0.4502 - val_accuracy: 0.7833\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4606 - accuracy: 0.7826 - val_loss: 0.4415 - val_accuracy: 0.7940\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.7820 - val_loss: 0.4335 - val_accuracy: 0.7977\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4541 - accuracy: 0.7846 - val_loss: 0.4621 - val_accuracy: 0.7737\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4498 - val_accuracy: 0.7927\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.7839 - val_loss: 0.4308 - val_accuracy: 0.8003\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.7831 - val_loss: 0.4102 - val_accuracy: 0.8063\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.7824 - val_loss: 0.4445 - val_accuracy: 0.7917\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4569 - accuracy: 0.7807 - val_loss: 0.4465 - val_accuracy: 0.7840\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.7843 - val_loss: 0.4538 - val_accuracy: 0.7923\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.7844 - val_loss: 0.4446 - val_accuracy: 0.7960\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.4337 - val_accuracy: 0.8030\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7803 - val_loss: 0.4370 - val_accuracy: 0.8023\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.7829 - val_loss: 0.4401 - val_accuracy: 0.7980\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7842 - val_loss: 0.4442 - val_accuracy: 0.7960\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.7822 - val_loss: 0.4209 - val_accuracy: 0.8033\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.7860 - val_loss: 0.4457 - val_accuracy: 0.7863\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.7837 - val_loss: 0.4246 - val_accuracy: 0.8033\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.7847 - val_loss: 0.4622 - val_accuracy: 0.7760\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.4452 - val_accuracy: 0.7933\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.7826 - val_loss: 0.4429 - val_accuracy: 0.7873\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7796 - val_loss: 0.4234 - val_accuracy: 0.7990\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.7864 - val_loss: 0.4404 - val_accuracy: 0.7920\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7861 - val_loss: 0.4192 - val_accuracy: 0.8167\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7872 - val_loss: 0.4403 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.4438 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.7804 - val_loss: 0.4412 - val_accuracy: 0.7893\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.7863 - val_loss: 0.4445 - val_accuracy: 0.7933\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.7864 - val_loss: 0.4218 - val_accuracy: 0.8127\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.7840 - val_loss: 0.4402 - val_accuracy: 0.7957\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7846 - val_loss: 0.4294 - val_accuracy: 0.7997\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.7814 - val_loss: 0.4441 - val_accuracy: 0.7940\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.4486 - val_accuracy: 0.7783\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4562 - accuracy: 0.7790 - val_loss: 0.4483 - val_accuracy: 0.7897\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.7872 - val_loss: 0.4357 - val_accuracy: 0.7940\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.7820 - val_loss: 0.4552 - val_accuracy: 0.7817\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.7808 - val_loss: 0.4348 - val_accuracy: 0.7890\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4559 - accuracy: 0.7870 - val_loss: 0.4420 - val_accuracy: 0.7900\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.7879 - val_loss: 0.4400 - val_accuracy: 0.7867\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4546 - accuracy: 0.7813 - val_loss: 0.4457 - val_accuracy: 0.7927\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7797 - val_loss: 0.4532 - val_accuracy: 0.7890\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.7847 - val_loss: 0.4379 - val_accuracy: 0.7920\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7873 - val_loss: 0.4206 - val_accuracy: 0.8110\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.7873 - val_loss: 0.4359 - val_accuracy: 0.7970\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.7837 - val_loss: 0.4540 - val_accuracy: 0.7820\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.7819 - val_loss: 0.4562 - val_accuracy: 0.7823\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.7829 - val_loss: 0.4238 - val_accuracy: 0.8047\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.7822 - val_loss: 0.4440 - val_accuracy: 0.7920\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.7805 - val_loss: 0.4514 - val_accuracy: 0.7937\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# adding the first input layer and the first hidden layer\n",
    "model.add(Dense(12, kernel_initializer = 'normal', activation = 'relu', input_shape = (x_train_final.shape[1],)))\n",
    "\n",
    "# adding batch normalization and dropout layer\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# adding the third hidden layer\n",
    "model.add(Dense(6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "\n",
    "# adding batch normalization and dropout layer\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# adding the output layer\n",
    "model.add(Dense(1, kernel_initializer = 'normal', activation = 'sigmoid'))\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fitting the model to the training set\n",
    "model_history = model.fit(\n",
    "    x_train_final, y_train_final, validation_data=(x_test_final, y_test_final), epochs=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.3.3 Final Model <a id=\"final_model_3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}